{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Classification, Random Forest and SVM on a Credit Risk Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/Users/antoinetroadec/Documents/GitHub/Credit_risk/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "### Importing data from the txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#importing the data in a DataFrame\n",
    "import pandas\n",
    "data = pandas.read_table(\"german.data-numeric.txt\",delim_whitespace=True,header=None,decimal= \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 25)\n"
     ]
    }
   ],
   "source": [
    "#shape of the table \n",
    "print(data.shape) # (2310, 21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#training sample\n",
    "data_train = data.sample(650)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(650, 25)\n"
     ]
    }
   ],
   "source": [
    "#shape of the table \n",
    "print(data_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#transformation into numpy matrix\n",
    "d_train = data_train.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#vector for the target attribute\n",
    "y_app = d_train[:,24]\n",
    "#matrix for the predictive attributes\n",
    "X_app = d_train[:,0:23]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_test=data[~data.index.isin(data_train.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(350, 25)\n"
     ]
    }
   ],
   "source": [
    "#shape of the table \n",
    "print(data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = data_test.as_matrix()[:,24] \n",
    "X_test = data_test.as_matrix()[:,0:23]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#module for the evaluation of the classifiers\n",
    "from sklearn import metrics\n",
    "#function for the performance evaluation\n",
    "def error_rate(model,y_test,X_test):\n",
    "#prediction\n",
    "    y_pred = model.predict(X_test)\n",
    "    #error rate = 1 - accuracy rate (success rate)\n",
    "    err = 1.0 - metrics.accuracy_score(y_test,y_pred)\n",
    "    #return\n",
    "    return err\n",
    "#end fonction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification tree\n",
    "### Decision tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Decision tree - importation of the class\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#instantiation\n",
    "dtree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#learning\n",
    "dtree.fit(X_app,y_app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generation of the output -> .dot format\n",
    "from sklearn import tree \n",
    "tree.export_graphviz(dtree,out_file=\"tree.dot\",feature_names=data_train.columns[0:23])\n",
    " #visualization with graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Importance\n",
      "0     0.120323\n",
      "1     0.111642\n",
      "2     0.043464\n",
      "3     0.145181\n",
      "4     0.055113\n",
      "5     0.039868\n",
      "6     0.043736\n",
      "7     0.066120\n",
      "8     0.042501\n",
      "9     0.151196\n",
      "10    0.043509\n",
      "11    0.036572\n",
      "12    0.016425\n",
      "13    0.019902\n",
      "14    0.002852\n",
      "15    0.002716\n",
      "16    0.017656\n",
      "17    0.019184\n",
      "18    0.007239\n",
      "19    0.000000\n",
      "20    0.005409\n",
      "21    0.009393\n",
      "22    0.000000\n"
     ]
    }
   ],
   "source": [
    "#importance of variables - 0 when the variable does not appear into the tree\n",
    "imp = {\"Importance\":dtree.feature_importances_}\n",
    "print(pandas.DataFrame(imp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.322857142857\n"
     ]
    }
   ],
   "source": [
    "#error rate\n",
    "print(error_rate(dtree,y_test,X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging\n",
    "20 trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'),\n",
      "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=20, n_jobs=1, oob_score=False,\n",
      "         random_state=None, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "#class bagging\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "#instantiation\n",
    "baggingTree = BaggingClassifier(DecisionTreeClassifier(),n_estimators=20)\n",
    "print(baggingTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=20, n_jobs=1, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training\n",
    "baggingTree.fit(X_app,y_app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.228571428571\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "print(error_rate(baggingTree,y_test,X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error rate came from 32.3%(tree) to 22.9% (bagging)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree number\n",
    "Whta is the best number of trees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.31742857  0.25614286  0.25214286  0.24185714  0.235       0.23142857\n",
      "  0.23014286]\n"
     ]
    }
   ],
   "source": [
    "#train-test function for a given m\n",
    "def train_test_bagging(m,X_app,y_app,X_test,y_test):\n",
    "    #instantiation\n",
    "    bag = BaggingClassifier(DecisionTreeClassifier(),n_estimators=m)\n",
    "    #fit the model\n",
    "    bag.fit(X_app,y_app)\n",
    "    #prediction and calculation of the error rate\n",
    "    return error_rate(bag,y_test,X_test)\n",
    "#end train-test\n",
    "#values of m to evaluate\n",
    "m_a_tester = [1,5,10,20,50,100,500]\n",
    "#initialization of the matrix for the results\n",
    "import numpy\n",
    "result = numpy.zeros(shape=(1,7))\n",
    "#repeat 20 times the experiment for m\n",
    "for expe in range(20):\n",
    "#evaluate each value of m\n",
    "    res = [train_test_bagging(m,X_app,y_app,X_test,y_test) for m in m_a_tester]\n",
    "    #the vector with 7 values is transformed in a matrix (1, 7)\n",
    "    res = numpy.asarray(res).reshape(1,7)\n",
    "    #add a new row in the matrix\n",
    "    result = numpy.append(result,res,axis=0)\n",
    "#\n",
    "#remove the first row\n",
    "result = numpy.delete(result,0,axis=0)\n",
    "#calculate the average of error rate for each m\n",
    "mresult = numpy.mean(result,axis=0)\n",
    "print(mresult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1093a70b8>]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#graphical tool\n",
    "import matplotlib.pyplot as plt\n",
    "#label of the axes\n",
    "plt.xlabel(\"m\")\n",
    "plt.ylabel(\"Err. Rate\")\n",
    "plt.plot(m_a_tester,mresult,linewidth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "500 trees is the best number\n",
    "\n",
    "Let's do it using scikit-learn now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mean: 0.65231, std: 0.03867, params: {'n_estimators': 1}, mean: 0.70000, std: 0.01604, params: {'n_estimators': 5}, mean: 0.73846, std: 0.00588, params: {'n_estimators': 10}, mean: 0.74923, std: 0.03020, params: {'n_estimators': 20}, mean: 0.76154, std: 0.01654, params: {'n_estimators': 50}, mean: 0.75385, std: 0.01532, params: {'n_estimators': 100}, mean: 0.76462, std: 0.00710, params: {'n_estimators': 500}]\n"
     ]
    }
   ],
   "source": [
    "# detecting the “optimal” number of trees\n",
    "# using the grid search tool\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "# the parameters to make vary\n",
    "# the name of the parameter must be explicit\n",
    "# we enumerate the values to try\n",
    "parametres = [{\"n_estimators\":[1,5,10,20,50,100,500]}]\n",
    "# instantiate the classifier\n",
    "bag = BaggingClassifier(DecisionTreeClassifier())\n",
    "#instantiation of the gris search tool\n",
    "#the metric used is the accuracy rate (error rate = 1 - accuracy rate)\n",
    "grid_bag = GridSearchCV(estimator=bag,param_grid=parametres,scoring=\"accuracy\")\n",
    "#launching the exploration\n",
    "grille_bag = grid_bag.fit(X_app,y_app)\n",
    "#print the results\n",
    "print(grille_bag.grid_scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.764615384615\n",
      "{'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "#best score\n",
    "print(grille_bag.best_score_)\n",
    "#parameter for the best score\n",
    "print(grille_bag.best_params_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24\n"
     ]
    }
   ],
   "source": [
    "#valuation of the best solution on the test set\n",
    "print(error_rate(grille_bag,y_test,X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "## n=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28\n",
      "[ 0.09868516  0.1166408   0.07614889  0.12864958  0.05127822  0.05604085\n",
      "  0.03597425  0.0495375   0.05963165  0.10042489  0.0374859   0.01984932\n",
      "  0.01451595  0.03104455  0.00366922  0.02643353  0.0098401   0.01743267\n",
      "  0.01030885  0.01165811  0.02282914  0.0057007   0.01622019]\n",
      "    Importance\n",
      "0     0.098685\n",
      "1     0.116641\n",
      "2     0.076149\n",
      "3     0.128650\n",
      "4     0.051278\n",
      "5     0.056041\n",
      "6     0.035974\n",
      "7     0.049537\n",
      "8     0.059632\n",
      "9     0.100425\n",
      "10    0.037486\n",
      "11    0.019849\n",
      "12    0.014516\n",
      "13    0.031045\n",
      "14    0.003669\n",
      "15    0.026434\n",
      "16    0.009840\n",
      "17    0.017433\n",
      "18    0.010309\n",
      "19    0.011658\n",
      "20    0.022829\n",
      "21    0.005701\n",
      "22    0.016220\n"
     ]
    }
   ],
   "source": [
    "# RandomForest class\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# instantiation\n",
    "rf = RandomForestClassifier(n_estimators=20)\n",
    "# training phase\n",
    "rf.fit(X_app,y_app)\n",
    "# test error rate\n",
    "print(error_rate(rf,y_test,X_test))\n",
    "# importance of variables...\n",
    "print(rf.feature_importances_)\n",
    "#with their names\n",
    "imp = {\"Importance\":rf.feature_importances_}\n",
    "print(pandas.DataFrame(imp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(algorithm='SAMME',\n",
      "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'),\n",
      "          learning_rate=1.0, n_estimators=20, random_state=None)\n",
      "0.311428571429\n"
     ]
    }
   ],
   "source": [
    "# Adaboost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# instantiation\n",
    "ab=AdaBoostClassifier(algorithm=\"SAMME\",n_estimators=20,base_estimator=\n",
    "                    DecisionTreeClassifier())\n",
    "print(ab)\n",
    "# training phase\n",
    "ab.fit(X_app,y_app)\n",
    "# test error rate\n",
    "print(error_rate(ab,y_test,X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.245714285714\n",
      "[ 0.10217331  0.1152557   0.06493912  0.12998077  0.05173975  0.05944774\n",
      "  0.04216673  0.05042849  0.05265149  0.11242279  0.03206363  0.02490707\n",
      "  0.01456531  0.02508909  0.00384332  0.02633619  0.01194166  0.01405179\n",
      "  0.01028584  0.01396855  0.01933744  0.00382522  0.018579  ]\n",
      "    Importance\n",
      "0     0.102173\n",
      "1     0.115256\n",
      "2     0.064939\n",
      "3     0.129981\n",
      "4     0.051740\n",
      "5     0.059448\n",
      "6     0.042167\n",
      "7     0.050428\n",
      "8     0.052651\n",
      "9     0.112423\n",
      "10    0.032064\n",
      "11    0.024907\n",
      "12    0.014565\n",
      "13    0.025089\n",
      "14    0.003843\n",
      "15    0.026336\n",
      "16    0.011942\n",
      "17    0.014052\n",
      "18    0.010286\n",
      "19    0.013969\n",
      "20    0.019337\n",
      "21    0.003825\n",
      "22    0.018579\n"
     ]
    }
   ],
   "source": [
    "# RandomForest class\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# instantiation\n",
    "rf = RandomForestClassifier(n_estimators=500)\n",
    "# training phase\n",
    "rf.fit(X_app,y_app)\n",
    "# test error rate\n",
    "print(error_rate(rf,y_test,X_test))\n",
    "# importance of variables...\n",
    "print(rf.feature_importances_)\n",
    "#with their names\n",
    "imp = {\"Importance\":rf.feature_importances_}\n",
    "print(pandas.DataFrame(imp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(algorithm='SAMME',\n",
      "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'),\n",
      "          learning_rate=1.0, n_estimators=500, random_state=None)\n",
      "0.311428571429\n"
     ]
    }
   ],
   "source": [
    "# Adaboost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# instantiation\n",
    "ab=AdaBoostClassifier(algorithm=\"SAMME\",n_estimators=500,base_estimator=\n",
    "                    DecisionTreeClassifier())\n",
    "print(ab)\n",
    "# training phase\n",
    "ab.fit(X_app,y_app)\n",
    "# test error rate\n",
    "print(error_rate(ab,y_test,X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24\n"
     ]
    }
   ],
   "source": [
    "# import SVM\n",
    "from sklearn import svm\n",
    "# instantiation\n",
    "svmmod = svm.SVC(kernel='linear', C=1)\n",
    "# training phase\n",
    "svmmod.fit(X_app,y_app)\n",
    "# test error rate\n",
    "print(error_rate(svmmod,y_test,X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "Neural Network is not available for scikit-learn .17 on Feb 2nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'MLPClassifier'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-135-8dd027ce5463>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# import Neural Network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# instantiation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mneural\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l-bfgs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_layer_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# training phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'MLPClassifier'"
     ]
    }
   ],
   "source": [
    "# import Neural Network\n",
    "from sklearn import MLPClassifier\n",
    "# instantiation\n",
    "neural = MLPClassifier(algorithm='l-bfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "# training phase\n",
    "neural.fit(X_app,y_app)\n",
    "# test error rate\n",
    "print(error_rate(neural,y_test,X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
